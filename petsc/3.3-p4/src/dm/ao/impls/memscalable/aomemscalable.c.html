<center><a href="aomemscalable.c">Actual source code: aomemscalable.c</a></center><br>

<html>
<head> <link rel="canonical" href="http://www.mcs.anl.gov/petsc/petsc-current/src/dm/ao/impls/memscalable/aomemscalable.c.html" />
<title></title>
<meta name="generator" content="c2html 0.9.5">
<meta name="date" content="2012-10-26T16:11:33+00:00">
</head>

<body bgcolor="#FFFFFF">
   <div id="version" align=right><b>petsc-3.3-p4 2012-10-26</b></div>
<pre width="80">
<a name="line2">  2: </a><font color="#B22222">/*</font>
<a name="line3">  3: </a><font color="#B22222">    The memory scalable <A href="../../../../../docs/manualpages/AO/AO.html#AO">AO</A> application ordering routines. These store the </font>
<a name="line4">  4: </a><font color="#B22222">  local orderings on each processor.</font>
<a name="line5">  5: </a><font color="#B22222">*/</font>

<a name="line7">  7: </a><font color="#A020F0">#include &lt;../src/dm/ao/aoimpl.h&gt;          </font><font color="#B22222">/*I  "petscao.h"   I*/</font><font color="#A020F0"></font>

<a name="line9">  9: </a><font color="#4169E1">typedef</font> <font color="#4169E1">struct</font> {
<a name="line10"> 10: </a>  <A href="../../../../../docs/manualpages/Sys/PetscInt.html#PetscInt">PetscInt</A>     *app_loc;   <font color="#B22222">/* app_loc[i] is the partner for the ith local PETSc slot */</font>
<a name="line11"> 11: </a>  <A href="../../../../../docs/manualpages/Sys/PetscInt.html#PetscInt">PetscInt</A>     *petsc_loc; <font color="#B22222">/* petsc_loc[j] is the partner for the jth local app slot */</font>
<a name="line12"> 12: </a>  <A href="../../../../../docs/manualpages/Vec/PetscLayout.html#PetscLayout">PetscLayout</A>  map;        <font color="#B22222">/* determines the local sizes of ao */</font>
<a name="line13"> 13: </a>} AO_MemoryScalable;

<a name="line15"> 15: </a><font color="#B22222">/*</font>
<a name="line16"> 16: </a><font color="#B22222">       All processors have the same data so processor 1 prints it</font>
<a name="line17"> 17: </a><font color="#B22222">*/</font>
<a name="line20"> 20: </a><strong><font color="#4169E1"><a name="AOView_MemoryScalable"></a><A href="../../../../../docs/manualpages/Sys/PetscErrorCode.html#PetscErrorCode">PetscErrorCode</A> AOView_MemoryScalable(<A href="../../../../../docs/manualpages/AO/AO.html#AO">AO</A> ao,<A href="../../../../../docs/manualpages/Viewer/PetscViewer.html#PetscViewer">PetscViewer</A> viewer)</font></strong>
<a name="line21"> 21: </a>{
<a name="line22"> 22: </a>  <A href="../../../../../docs/manualpages/Sys/PetscErrorCode.html#PetscErrorCode">PetscErrorCode</A>    ierr;
<a name="line23"> 23: </a>  <A href="../../../../../docs/manualpages/Sys/PetscMPIInt.html#PetscMPIInt">PetscMPIInt</A>       rank,size;
<a name="line24"> 24: </a>  AO_MemoryScalable *aomems = (AO_MemoryScalable*)ao-&gt;data;
<a name="line25"> 25: </a>  <A href="../../../../../docs/manualpages/Sys/PetscBool.html#PetscBool">PetscBool</A>         iascii;
<a name="line26"> 26: </a>  <A href="../../../../../docs/manualpages/Sys/PetscMPIInt.html#PetscMPIInt">PetscMPIInt</A>       tag_app,tag_petsc;
<a name="line27"> 27: </a>  <A href="../../../../../docs/manualpages/Vec/PetscLayout.html#PetscLayout">PetscLayout</A>       map = aomems-&gt;map;
<a name="line28"> 28: </a>  <A href="../../../../../docs/manualpages/Sys/PetscInt.html#PetscInt">PetscInt</A>          *app,*app_loc,*petsc,*petsc_loc,len,i,j;
<a name="line29"> 29: </a>  MPI_Status        status;

<a name="line32"> 32: </a>  <A href="../../../../../docs/manualpages/Sys/PetscObjectTypeCompare.html#PetscObjectTypeCompare">PetscObjectTypeCompare</A>((<A href="../../../../../docs/manualpages/Sys/PetscObject.html#PetscObject">PetscObject</A>)viewer,PETSCVIEWERASCII,&amp;iascii);
<a name="line33"> 33: </a>  <font color="#4169E1">if</font> (!iascii) <A href="../../../../../docs/manualpages/Sys/SETERRQ1.html#SETERRQ1">SETERRQ1</A>(((<A href="../../../../../docs/manualpages/Sys/PetscObject.html#PetscObject">PetscObject</A>)viewer)-&gt;comm,PETSC_ERR_SUP,<font color="#666666">"Viewer type %s not supported for <A href="../../../../../docs/manualpages/AO/AO.html#AO">AO</A> MemoryScalable"</font>,((<A href="../../../../../docs/manualpages/Sys/PetscObject.html#PetscObject">PetscObject</A>)viewer)-&gt;type_name);

<a name="line35"> 35: </a>  <A href="http://www.mcs.anl.gov/mpi/www/www3/MPI_Comm_rank.html#MPI_Comm_rank">MPI_Comm_rank</A>(((<A href="../../../../../docs/manualpages/Sys/PetscObject.html#PetscObject">PetscObject</A>)ao)-&gt;comm,&amp;rank);
<a name="line36"> 36: </a>  <A href="http://www.mcs.anl.gov/mpi/www/www3/MPI_Comm_size.html#MPI_Comm_size">MPI_Comm_size</A>(((<A href="../../../../../docs/manualpages/Sys/PetscObject.html#PetscObject">PetscObject</A>)ao)-&gt;comm,&amp;size);
<a name="line37"> 37: </a>
<a name="line38"> 38: </a>  <A href="../../../../../docs/manualpages/Sys/PetscObjectGetNewTag.html#PetscObjectGetNewTag">PetscObjectGetNewTag</A>((<A href="../../../../../docs/manualpages/Sys/PetscObject.html#PetscObject">PetscObject</A>)ao,&amp;tag_app);
<a name="line39"> 39: </a>  <A href="../../../../../docs/manualpages/Sys/PetscObjectGetNewTag.html#PetscObjectGetNewTag">PetscObjectGetNewTag</A>((<A href="../../../../../docs/manualpages/Sys/PetscObject.html#PetscObject">PetscObject</A>)ao,&amp;tag_petsc);

<a name="line41"> 41: </a>  <font color="#4169E1">if</font> (!rank){
<a name="line42"> 42: </a>    <A href="../../../../../docs/manualpages/Viewer/PetscViewerASCIIPrintf.html#PetscViewerASCIIPrintf">PetscViewerASCIIPrintf</A>(viewer,<font color="#666666">"Number of elements in ordering %D\n"</font>,ao-&gt;N);
<a name="line43"> 43: </a>    <A href="../../../../../docs/manualpages/Viewer/PetscViewerASCIIPrintf.html#PetscViewerASCIIPrintf">PetscViewerASCIIPrintf</A>(viewer,  <font color="#666666">"PETSc-&gt;App  App-&gt;PETSc\n"</font>);

<a name="line45"> 45: </a>    <A href="../../../../../docs/manualpages/Sys/PetscMalloc2.html#PetscMalloc2">PetscMalloc2</A>(map-&gt;N,<A href="../../../../../docs/manualpages/Sys/PetscInt.html#PetscInt">PetscInt</A>,&amp;app,map-&gt;N,<A href="../../../../../docs/manualpages/Sys/PetscInt.html#PetscInt">PetscInt</A>,&amp;petsc);
<a name="line46"> 46: </a>    len = map-&gt;n;
<a name="line47"> 47: </a>    <font color="#B22222">/* print local <A href="../../../../../docs/manualpages/AO/AO.html#AO">AO</A> */</font>
<a name="line48"> 48: </a>    <A href="../../../../../docs/manualpages/Viewer/PetscViewerASCIIPrintf.html#PetscViewerASCIIPrintf">PetscViewerASCIIPrintf</A>(viewer,<font color="#666666">"Process [%D]\n"</font>,rank);
<a name="line49"> 49: </a>    <font color="#4169E1">for</font> (i=0; i&lt;len; i++){
<a name="line50"> 50: </a>      <A href="../../../../../docs/manualpages/Viewer/PetscViewerASCIIPrintf.html#PetscViewerASCIIPrintf">PetscViewerASCIIPrintf</A>(viewer,<font color="#666666">"%3D  %3D    %3D  %3D\n"</font>,i,aomems-&gt;app_loc[i],i,aomems-&gt;petsc_loc[i]);
<a name="line51"> 51: </a>    }

<a name="line53"> 53: </a>    <font color="#B22222">/* recv and print off-processor's <A href="../../../../../docs/manualpages/AO/AO.html#AO">AO</A> */</font>
<a name="line54"> 54: </a>    <font color="#4169E1">for</font> (i=1; i&lt;size; i++) {
<a name="line55"> 55: </a>      len = map-&gt;range[i+1] - map-&gt;range[i];
<a name="line56"> 56: </a>      app_loc   = app  + map-&gt;range[i];
<a name="line57"> 57: </a>      petsc_loc = petsc+ map-&gt;range[i];
<a name="line58"> 58: </a>      <A href="http://www.mcs.anl.gov/mpi/www/www3/MPI_Recv.html#MPI_Recv">MPI_Recv</A>(app_loc,(<A href="../../../../../docs/manualpages/Sys/PetscMPIInt.html#PetscMPIInt">PetscMPIInt</A>)len,MPIU_INT,i,tag_app,((<A href="../../../../../docs/manualpages/Sys/PetscObject.html#PetscObject">PetscObject</A>)ao)-&gt;comm,&amp;status);
<a name="line59"> 59: </a>      <A href="http://www.mcs.anl.gov/mpi/www/www3/MPI_Recv.html#MPI_Recv">MPI_Recv</A>(petsc_loc,(<A href="../../../../../docs/manualpages/Sys/PetscMPIInt.html#PetscMPIInt">PetscMPIInt</A>)len,MPIU_INT,i,tag_petsc,((<A href="../../../../../docs/manualpages/Sys/PetscObject.html#PetscObject">PetscObject</A>)ao)-&gt;comm,&amp;status);
<a name="line60"> 60: </a>      <A href="../../../../../docs/manualpages/Viewer/PetscViewerASCIIPrintf.html#PetscViewerASCIIPrintf">PetscViewerASCIIPrintf</A>(viewer,<font color="#666666">"Process [%D]\n"</font>,i);
<a name="line61"> 61: </a>      <font color="#4169E1">for</font> (j=0; j&lt;len; j++) {
<a name="line62"> 62: </a>        <A href="../../../../../docs/manualpages/Viewer/PetscViewerASCIIPrintf.html#PetscViewerASCIIPrintf">PetscViewerASCIIPrintf</A>(viewer,<font color="#666666">"%3D  %3D    %3D  %3D\n"</font>,map-&gt;range[i]+j,app_loc[j],map-&gt;range[i]+j,petsc_loc[j]);
<a name="line63"> 63: </a>      }
<a name="line64"> 64: </a>    }
<a name="line65"> 65: </a>    <A href="../../../../../docs/manualpages/Sys/PetscFree2.html#PetscFree2">PetscFree2</A>(app,petsc);
<a name="line66"> 66: </a>
<a name="line67"> 67: </a>  } <font color="#4169E1">else</font> {
<a name="line68"> 68: </a>    <font color="#B22222">/* send values */</font>
<a name="line69"> 69: </a>    <A href="http://www.mcs.anl.gov/mpi/www/www3/MPI_Send.html#MPI_Send">MPI_Send</A>((void*)aomems-&gt;app_loc,map-&gt;n,MPIU_INT,0,tag_app,((<A href="../../../../../docs/manualpages/Sys/PetscObject.html#PetscObject">PetscObject</A>)ao)-&gt;comm);
<a name="line70"> 70: </a>    <A href="http://www.mcs.anl.gov/mpi/www/www3/MPI_Send.html#MPI_Send">MPI_Send</A>((void*)aomems-&gt;petsc_loc,map-&gt;n,MPIU_INT,0,tag_petsc,((<A href="../../../../../docs/manualpages/Sys/PetscObject.html#PetscObject">PetscObject</A>)ao)-&gt;comm);
<a name="line71"> 71: </a>  }
<a name="line72"> 72: </a>  <A href="../../../../../docs/manualpages/Viewer/PetscViewerFlush.html#PetscViewerFlush">PetscViewerFlush</A>(viewer);
<a name="line73"> 73: </a>  <font color="#4169E1">return</font>(0);
<a name="line74"> 74: </a>}

<a name="line78"> 78: </a><strong><font color="#4169E1"><a name="AODestroy_MemoryScalable"></a><A href="../../../../../docs/manualpages/Sys/PetscErrorCode.html#PetscErrorCode">PetscErrorCode</A> AODestroy_MemoryScalable(<A href="../../../../../docs/manualpages/AO/AO.html#AO">AO</A> ao)</font></strong>
<a name="line79"> 79: </a>{
<a name="line80"> 80: </a>  AO_MemoryScalable *aomems = (AO_MemoryScalable*)ao-&gt;data;
<a name="line81"> 81: </a>  <A href="../../../../../docs/manualpages/Sys/PetscErrorCode.html#PetscErrorCode">PetscErrorCode</A>    ierr;

<a name="line84"> 84: </a>  <A href="../../../../../docs/manualpages/Sys/PetscFree2.html#PetscFree2">PetscFree2</A>(aomems-&gt;app_loc,aomems-&gt;petsc_loc);
<a name="line85"> 85: </a>  <A href="../../../../../docs/manualpages/Vec/PetscLayoutDestroy.html#PetscLayoutDestroy">PetscLayoutDestroy</A>(&amp;aomems-&gt;map);
<a name="line86"> 86: </a>  <A href="../../../../../docs/manualpages/Sys/PetscFree.html#PetscFree">PetscFree</A>(aomems);
<a name="line87"> 87: </a>  <font color="#4169E1">return</font>(0);
<a name="line88"> 88: </a>}

<a name="line90"> 90: </a><font color="#B22222">/*</font>
<a name="line91"> 91: </a><font color="#B22222">   Input Parameters:</font>
<a name="line92"> 92: </a><font color="#B22222">+   ao - the application ordering context</font>
<a name="line93"> 93: </a><font color="#B22222">.   n  - the number of integers in ia[]</font>
<a name="line94"> 94: </a><font color="#B22222">.   ia - the integers; these are replaced with their mapped value</font>
<a name="line95"> 95: </a><font color="#B22222">-   maploc - app_loc or petsc_loc in struct "AO_MemoryScalable" </font>

<a name="line97"> 97: </a><font color="#B22222">   Output Parameter:</font>
<a name="line98"> 98: </a><font color="#B22222">.   ia - the mapped interges</font>
<a name="line99"> 99: </a><font color="#B22222"> */</font>
<a name="line102">102: </a><strong><font color="#4169E1"><a name="AOMap_MemoryScalable_private"></a><A href="../../../../../docs/manualpages/Sys/PetscErrorCode.html#PetscErrorCode">PetscErrorCode</A> AOMap_MemoryScalable_private(<A href="../../../../../docs/manualpages/AO/AO.html#AO">AO</A> ao,<A href="../../../../../docs/manualpages/Sys/PetscInt.html#PetscInt">PetscInt</A> n,<A href="../../../../../docs/manualpages/Sys/PetscInt.html#PetscInt">PetscInt</A> *ia,<A href="../../../../../docs/manualpages/Sys/PetscInt.html#PetscInt">PetscInt</A> *maploc)</font></strong>
<a name="line103">103: </a>{
<a name="line104">104: </a>  <A href="../../../../../docs/manualpages/Sys/PetscErrorCode.html#PetscErrorCode">PetscErrorCode</A>    ierr;
<a name="line105">105: </a>  AO_MemoryScalable *aomems = (AO_MemoryScalable*)ao-&gt;data;
<a name="line106">106: </a>  <A href="../../../../../docs/manualpages/Sys/MPI_Comm.html#MPI_Comm">MPI_Comm</A>          comm=((<A href="../../../../../docs/manualpages/Sys/PetscObject.html#PetscObject">PetscObject</A>)ao)-&gt;comm;
<a name="line107">107: </a>  <A href="../../../../../docs/manualpages/Sys/PetscMPIInt.html#PetscMPIInt">PetscMPIInt</A>       rank,size,tag1,tag2;
<a name="line108">108: </a>  <A href="../../../../../docs/manualpages/Sys/PetscInt.html#PetscInt">PetscInt</A>          *owner,*start,*nprocs,nsends,nreceives;
<a name="line109">109: </a>  <A href="../../../../../docs/manualpages/Sys/PetscInt.html#PetscInt">PetscInt</A>          nmax,count,*sindices,*rindices,i,j,idx,lastidx,*sindices2,*rindices2;
<a name="line110">110: </a>  <A href="../../../../../docs/manualpages/Sys/PetscInt.html#PetscInt">PetscInt</A>          *owners = aomems-&gt;map-&gt;range;
<a name="line111">111: </a>  MPI_Request       *send_waits,*recv_waits,*send_waits2,*recv_waits2;
<a name="line112">112: </a>  MPI_Status        recv_status;
<a name="line113">113: </a>  <A href="../../../../../docs/manualpages/Sys/PetscMPIInt.html#PetscMPIInt">PetscMPIInt</A>       nindices,source,widx;
<a name="line114">114: </a>  <A href="../../../../../docs/manualpages/Sys/PetscInt.html#PetscInt">PetscInt</A>          *rbuf,*sbuf;
<a name="line115">115: </a>  MPI_Status        *send_status,*send_status2;
<a name="line116">116: </a>
<a name="line118">118: </a>  <A href="http://www.mcs.anl.gov/mpi/www/www3/MPI_Comm_rank.html#MPI_Comm_rank">MPI_Comm_rank</A>(comm,&amp;rank);
<a name="line119">119: </a>  <A href="http://www.mcs.anl.gov/mpi/www/www3/MPI_Comm_size.html#MPI_Comm_size">MPI_Comm_size</A>(comm,&amp;size);

<a name="line121">121: </a>  <font color="#B22222">/*  first count number of contributors to each processor */</font>
<a name="line122">122: </a>  <A href="../../../../../docs/manualpages/Sys/PetscMalloc2.html#PetscMalloc2">PetscMalloc2</A>(2*size,<A href="../../../../../docs/manualpages/Sys/PetscInt.html#PetscInt">PetscInt</A>,&amp;nprocs,size,<A href="../../../../../docs/manualpages/Sys/PetscInt.html#PetscInt">PetscInt</A>,&amp;start);
<a name="line123">123: </a>  <A href="../../../../../docs/manualpages/Sys/PetscMemzero.html#PetscMemzero">PetscMemzero</A>(nprocs,2*size*<font color="#4169E1">sizeof</font>(<A href="../../../../../docs/manualpages/Sys/PetscInt.html#PetscInt">PetscInt</A>));
<a name="line124">124: </a>  <A href="../../../../../docs/manualpages/Sys/PetscMalloc.html#PetscMalloc">PetscMalloc</A>(n*<font color="#4169E1">sizeof</font>(<A href="../../../../../docs/manualpages/Sys/PetscInt.html#PetscInt">PetscInt</A>),&amp;owner);
<a name="line125">125: </a>  <A href="../../../../../docs/manualpages/Sys/PetscMemzero.html#PetscMemzero">PetscMemzero</A>(owner,n*<font color="#4169E1">sizeof</font>(<A href="../../../../../docs/manualpages/Sys/PetscInt.html#PetscInt">PetscInt</A>));
<a name="line126">126: </a>
<a name="line127">127: </a>  j       = 0;
<a name="line128">128: </a>  lastidx = -1;
<a name="line129">129: </a>  <font color="#4169E1">for</font> (i=0; i&lt;n; i++) {
<a name="line130">130: </a>    <font color="#B22222">/* if indices are NOT locally sorted, need to start search at the beginning */</font>
<a name="line131">131: </a>    <font color="#4169E1">if</font> (lastidx &gt; (idx = ia[i])) j = 0;
<a name="line132">132: </a>    lastidx = idx;
<a name="line133">133: </a>    <font color="#4169E1">for</font> (; j&lt;size; j++) {
<a name="line134">134: </a>      <font color="#4169E1">if</font> (idx &gt;= owners[j] &amp;&amp; idx &lt; owners[j+1]) {
<a name="line135">135: </a>        nprocs[2*j]++;     <font color="#B22222">/* num of indices to be sent */</font>
<a name="line136">136: </a>        nprocs[2*j+1] = 1; <font color="#B22222">/* send to proc[j] */</font>
<a name="line137">137: </a>        owner[i] = j;
<a name="line138">138: </a>        <font color="#4169E1">break</font>;
<a name="line139">139: </a>      }
<a name="line140">140: </a>    }
<a name="line141">141: </a>  }
<a name="line142">142: </a>  nprocs[2*rank]=nprocs[2*rank+1]=0; <font color="#B22222">/* do not receive from self! */</font>
<a name="line143">143: </a>  nsends = 0;
<a name="line144">144: </a>  <font color="#4169E1">for</font> (i=0; i&lt;size; i++) nsends += nprocs[2*i+1];

<a name="line146">146: </a>  <font color="#B22222">/* inform other processors of number of messages and max length*/</font>
<a name="line147">147: </a>  PetscMaxSum(comm,nprocs,&amp;nmax,&amp;nreceives);
<a name="line148">148: </a>
<a name="line149">149: </a>  <font color="#B22222">/* allocate arrays */</font>
<a name="line150">150: </a>  <A href="../../../../../docs/manualpages/Sys/PetscObjectGetNewTag.html#PetscObjectGetNewTag">PetscObjectGetNewTag</A>((<A href="../../../../../docs/manualpages/Sys/PetscObject.html#PetscObject">PetscObject</A>)ao,&amp;tag1);
<a name="line151">151: </a>  <A href="../../../../../docs/manualpages/Sys/PetscObjectGetNewTag.html#PetscObjectGetNewTag">PetscObjectGetNewTag</A>((<A href="../../../../../docs/manualpages/Sys/PetscObject.html#PetscObject">PetscObject</A>)ao,&amp;tag2);

<a name="line153">153: </a>  <A href="../../../../../docs/manualpages/Sys/PetscMalloc2.html#PetscMalloc2">PetscMalloc2</A>(nreceives*nmax,<A href="../../../../../docs/manualpages/Sys/PetscInt.html#PetscInt">PetscInt</A>,&amp;rindices,nreceives,MPI_Request,&amp;recv_waits);
<a name="line154">154: </a>  <A href="../../../../../docs/manualpages/Sys/PetscMalloc2.html#PetscMalloc2">PetscMalloc2</A>(nsends*nmax,<A href="../../../../../docs/manualpages/Sys/PetscInt.html#PetscInt">PetscInt</A>,&amp;rindices2,nsends,MPI_Request,&amp;recv_waits2);
<a name="line155">155: </a>
<a name="line156">156: </a>  <A href="../../../../../docs/manualpages/Sys/PetscMalloc3.html#PetscMalloc3">PetscMalloc3</A>(n,<A href="../../../../../docs/manualpages/Sys/PetscInt.html#PetscInt">PetscInt</A>,&amp;sindices,nsends,MPI_Request,&amp;send_waits,nsends,MPI_Status,&amp;send_status);
<a name="line157">157: </a>  <A href="../../../../../docs/manualpages/Sys/PetscMalloc3.html#PetscMalloc3">PetscMalloc3</A>(n,<A href="../../../../../docs/manualpages/Sys/PetscInt.html#PetscInt">PetscInt</A>,&amp;sindices2,nreceives,MPI_Request,&amp;send_waits2,nreceives,MPI_Status,&amp;send_status2);

<a name="line159">159: </a>  <font color="#B22222">/* post 1st receives: receive others requests</font>
<a name="line160">160: </a><font color="#B22222">     since we don't know how long each individual message is we </font>
<a name="line161">161: </a><font color="#B22222">     allocate the largest needed buffer for each receive. Potentially </font>
<a name="line162">162: </a><font color="#B22222">     this is a lot of wasted space.</font>
<a name="line163">163: </a><font color="#B22222">  */</font>
<a name="line164">164: </a>  <font color="#4169E1">for</font> (i=0,count=0; i&lt;nreceives; i++) {
<a name="line165">165: </a>    <A href="http://www.mcs.anl.gov/mpi/www/www3/MPI_Irecv.html#MPI_Irecv">MPI_Irecv</A>(rindices+nmax*i,nmax,MPIU_INT,MPI_ANY_SOURCE,tag1,comm,recv_waits+count++);
<a name="line166">166: </a>  }

<a name="line168">168: </a>  <font color="#B22222">/* do 1st sends: </font>
<a name="line169">169: </a><font color="#B22222">      1) starts[i] gives the starting index in svalues for stuff going to </font>
<a name="line170">170: </a><font color="#B22222">         the ith processor</font>
<a name="line171">171: </a><font color="#B22222">  */</font>
<a name="line172">172: </a>  start[0] = 0;
<a name="line173">173: </a>  <font color="#4169E1">for</font> (i=1; i&lt;size; i++) start[i] = start[i-1] + nprocs[2*i-2];
<a name="line174">174: </a>  <font color="#4169E1">for</font> (i=0; i&lt;n; i++) {
<a name="line175">175: </a>    j = owner[i];
<a name="line176">176: </a>    <font color="#4169E1">if</font> (j != rank){
<a name="line177">177: </a>      sindices[start[j]++]  = ia[i];
<a name="line178">178: </a>    } <font color="#4169E1">else</font> { <font color="#B22222">/* compute my own map */</font>
<a name="line179">179: </a>      <font color="#4169E1">if</font> (ia[i] &gt;= owners[rank] &amp;&amp; ia[i] &lt; owners[rank+1] ) {
<a name="line180">180: </a>        ia[i] = maploc[ia[i]-owners[rank]];
<a name="line181">181: </a>      } <font color="#4169E1">else</font> {
<a name="line182">182: </a>        ia[i] = -1 ; <font color="#B22222">/* ia[i] is not in the range of 0 and N-1, maps it to -1 */</font>
<a name="line183">183: </a>      }
<a name="line184">184: </a>    }
<a name="line185">185: </a>  }

<a name="line187">187: </a>  start[0] = 0;
<a name="line188">188: </a>  <font color="#4169E1">for</font> (i=1; i&lt;size; i++) { start[i] = start[i-1] + nprocs[2*i-2];}
<a name="line189">189: </a>  <font color="#4169E1">for</font> (i=0,count=0; i&lt;size; i++) {
<a name="line190">190: </a>    <font color="#4169E1">if</font> (nprocs[2*i+1]) {
<a name="line191">191: </a>      <font color="#B22222">/* send my request to others */</font>
<a name="line192">192: </a>      <A href="http://www.mcs.anl.gov/mpi/www/www3/MPI_Isend.html#MPI_Isend">MPI_Isend</A>(sindices+start[i],nprocs[2*i],MPIU_INT,i,tag1,comm,send_waits+count);
<a name="line193">193: </a>      <font color="#B22222">/* post receive for the answer of my request */</font>
<a name="line194">194: </a>      <A href="http://www.mcs.anl.gov/mpi/www/www3/MPI_Irecv.html#MPI_Irecv">MPI_Irecv</A>(sindices2+start[i],nprocs[2*i],MPIU_INT,i,tag2,comm,recv_waits2+count);
<a name="line195">195: </a>      count++;
<a name="line196">196: </a>    }
<a name="line197">197: </a>  }
<a name="line198">198: </a>  <font color="#4169E1">if</font> (nsends != count) <A href="../../../../../docs/manualpages/Sys/SETERRQ2.html#SETERRQ2">SETERRQ2</A>(comm,PETSC_ERR_SUP,<font color="#666666">"nsends %d != count %d"</font>,nsends,count);

<a name="line200">200: </a>  <font color="#B22222">/* wait on 1st sends */</font>
<a name="line201">201: </a>  <font color="#4169E1">if</font> (nsends) {
<a name="line202">202: </a>    <A href="http://www.mcs.anl.gov/mpi/www/www3/MPI_Waitall.html#MPI_Waitall">MPI_Waitall</A>(nsends,send_waits,send_status);
<a name="line203">203: </a>  }
<a name="line204">204: </a>
<a name="line205">205: </a>  <font color="#B22222">/* 1st recvs: other's requests */</font>
<a name="line206">206: </a>  <font color="#4169E1">for</font> (j=0; j&lt; nreceives; j++){
<a name="line207">207: </a>    <A href="http://www.mcs.anl.gov/mpi/www/www3/MPI_Waitany.html#MPI_Waitany">MPI_Waitany</A>(nreceives,recv_waits,&amp;widx,&amp;recv_status); <font color="#B22222">/* idx: index of handle for operation that completed */</font>
<a name="line208">208: </a>    <A href="http://www.mcs.anl.gov/mpi/www/www3/MPI_Get_count.html#MPI_Get_count">MPI_Get_count</A>(&amp;recv_status,MPIU_INT,&amp;nindices);
<a name="line209">209: </a>    rbuf = rindices+nmax*widx; <font color="#B22222">/* global index */</font>
<a name="line210">210: </a>    source = recv_status.MPI_SOURCE;
<a name="line211">211: </a>
<a name="line212">212: </a>    <font color="#B22222">/* compute mapping */</font>
<a name="line213">213: </a>    sbuf = rbuf;
<a name="line214">214: </a>    <font color="#4169E1">for</font> (i=0; i&lt;nindices; i++)sbuf[i] = maploc[rbuf[i]-owners[rank]];

<a name="line216">216: </a>    <font color="#B22222">/* send mapping back to the sender */</font>
<a name="line217">217: </a>    <A href="http://www.mcs.anl.gov/mpi/www/www3/MPI_Isend.html#MPI_Isend">MPI_Isend</A>(sbuf,nindices,MPIU_INT,source,tag2,comm,send_waits2+widx);
<a name="line218">218: </a>  }

<a name="line220">220: </a>  <font color="#B22222">/* wait on 2nd sends */</font>
<a name="line221">221: </a>  <font color="#4169E1">if</font> (nreceives) {
<a name="line222">222: </a>    <A href="http://www.mcs.anl.gov/mpi/www/www3/MPI_Waitall.html#MPI_Waitall">MPI_Waitall</A>(nreceives,send_waits2,send_status2);
<a name="line223">223: </a>  }

<a name="line225">225: </a>  <font color="#B22222">/* 2nd recvs: for the answer of my request */</font>
<a name="line226">226: </a>  <font color="#4169E1">for</font> (j=0; j&lt; nsends; j++){
<a name="line227">227: </a>    <A href="http://www.mcs.anl.gov/mpi/www/www3/MPI_Waitany.html#MPI_Waitany">MPI_Waitany</A>(nsends,recv_waits2,&amp;widx,&amp;recv_status);
<a name="line228">228: </a>    <A href="http://www.mcs.anl.gov/mpi/www/www3/MPI_Get_count.html#MPI_Get_count">MPI_Get_count</A>(&amp;recv_status,MPIU_INT,&amp;nindices);
<a name="line229">229: </a>    source = recv_status.MPI_SOURCE;
<a name="line230">230: </a>    <font color="#B22222">/* pack output ia[] */</font>
<a name="line231">231: </a>    rbuf=sindices2+start[source];
<a name="line232">232: </a>    count=0;
<a name="line233">233: </a>    <font color="#4169E1">for</font> (i=0; i&lt;n; i++){
<a name="line234">234: </a>      <font color="#4169E1">if</font> (source == owner[i]) ia[i] = rbuf[count++];
<a name="line235">235: </a>    }
<a name="line236">236: </a>  }

<a name="line238">238: </a>  <font color="#B22222">/* free arrays */</font>
<a name="line239">239: </a>  <A href="../../../../../docs/manualpages/Sys/PetscFree2.html#PetscFree2">PetscFree2</A>(nprocs,start);
<a name="line240">240: </a>  <A href="../../../../../docs/manualpages/Sys/PetscFree.html#PetscFree">PetscFree</A>(owner);
<a name="line241">241: </a>  <A href="../../../../../docs/manualpages/Sys/PetscFree2.html#PetscFree2">PetscFree2</A>(rindices,recv_waits);
<a name="line242">242: </a>  <A href="../../../../../docs/manualpages/Sys/PetscFree2.html#PetscFree2">PetscFree2</A>(rindices2,recv_waits2);
<a name="line243">243: </a>  <A href="../../../../../docs/manualpages/Sys/PetscFree3.html#PetscFree3">PetscFree3</A>(sindices,send_waits,send_status);
<a name="line244">244: </a>  <A href="../../../../../docs/manualpages/Sys/PetscFree3.html#PetscFree3">PetscFree3</A>(sindices2,send_waits2,send_status2);
<a name="line245">245: </a>  <font color="#4169E1">return</font>(0);
<a name="line246">246: </a>}

<a name="line250">250: </a><strong><font color="#4169E1"><a name="AOPetscToApplication_MemoryScalable"></a><A href="../../../../../docs/manualpages/Sys/PetscErrorCode.html#PetscErrorCode">PetscErrorCode</A> AOPetscToApplication_MemoryScalable(<A href="../../../../../docs/manualpages/AO/AO.html#AO">AO</A> ao,<A href="../../../../../docs/manualpages/Sys/PetscInt.html#PetscInt">PetscInt</A> n,<A href="../../../../../docs/manualpages/Sys/PetscInt.html#PetscInt">PetscInt</A> *ia)</font></strong>
<a name="line251">251: </a>{
<a name="line252">252: </a>  <A href="../../../../../docs/manualpages/Sys/PetscErrorCode.html#PetscErrorCode">PetscErrorCode</A>    ierr;
<a name="line253">253: </a>  AO_MemoryScalable *aomems = (AO_MemoryScalable*)ao-&gt;data;
<a name="line254">254: </a>  <A href="../../../../../docs/manualpages/Sys/PetscInt.html#PetscInt">PetscInt</A>          *app_loc = aomems-&gt;app_loc;

<a name="line257">257: </a>  AOMap_MemoryScalable_private(ao,n,ia,app_loc);
<a name="line258">258: </a>  <font color="#4169E1">return</font>(0);
<a name="line259">259: </a>}

<a name="line263">263: </a><strong><font color="#4169E1"><a name="AOApplicationToPetsc_MemoryScalable"></a><A href="../../../../../docs/manualpages/Sys/PetscErrorCode.html#PetscErrorCode">PetscErrorCode</A> AOApplicationToPetsc_MemoryScalable(<A href="../../../../../docs/manualpages/AO/AO.html#AO">AO</A> ao,<A href="../../../../../docs/manualpages/Sys/PetscInt.html#PetscInt">PetscInt</A> n,<A href="../../../../../docs/manualpages/Sys/PetscInt.html#PetscInt">PetscInt</A> *ia)</font></strong>
<a name="line264">264: </a>{
<a name="line265">265: </a>  <A href="../../../../../docs/manualpages/Sys/PetscErrorCode.html#PetscErrorCode">PetscErrorCode</A>    ierr;
<a name="line266">266: </a>  AO_MemoryScalable *aomems = (AO_MemoryScalable*)ao-&gt;data;
<a name="line267">267: </a>  <A href="../../../../../docs/manualpages/Sys/PetscInt.html#PetscInt">PetscInt</A>          *petsc_loc = aomems-&gt;petsc_loc;

<a name="line270">270: </a>  AOMap_MemoryScalable_private(ao,n,ia,petsc_loc);
<a name="line271">271: </a>  <font color="#4169E1">return</font>(0);
<a name="line272">272: </a>}

<a name="line274">274: </a>static <font color="#4169E1">struct _AOOps</font> AOOps_MemoryScalable = {
<a name="line275">275: </a>       AOView_MemoryScalable,
<a name="line276">276: </a>       AODestroy_MemoryScalable,
<a name="line277">277: </a>       AOPetscToApplication_MemoryScalable,
<a name="line278">278: </a>       AOApplicationToPetsc_MemoryScalable,
<a name="line279">279: </a>       0,
<a name="line280">280: </a>       0,
<a name="line281">281: </a>       0,
<a name="line282">282: </a>       0
<a name="line283">283: </a>};

<a name="line287">287: </a><strong><font color="#4169E1"><a name="AOCreateMemoryScalable_private"></a><A href="../../../../../docs/manualpages/Sys/PetscErrorCode.html#PetscErrorCode">PetscErrorCode</A>  AOCreateMemoryScalable_private(<A href="../../../../../docs/manualpages/Sys/MPI_Comm.html#MPI_Comm">MPI_Comm</A> comm,<A href="../../../../../docs/manualpages/Sys/PetscInt.html#PetscInt">PetscInt</A> napp,const <A href="../../../../../docs/manualpages/Sys/PetscInt.html#PetscInt">PetscInt</A> from_array[],const <A href="../../../../../docs/manualpages/Sys/PetscInt.html#PetscInt">PetscInt</A> to_array[],<A href="../../../../../docs/manualpages/AO/AO.html#AO">AO</A> ao, <A href="../../../../../docs/manualpages/Sys/PetscInt.html#PetscInt">PetscInt</A> *aomap_loc)</font></strong>
<a name="line288">288: </a>{
<a name="line289">289: </a>  <A href="../../../../../docs/manualpages/Sys/PetscErrorCode.html#PetscErrorCode">PetscErrorCode</A>    ierr;
<a name="line290">290: </a>  AO_MemoryScalable *aomems=(AO_MemoryScalable*)ao-&gt;data;
<a name="line291">291: </a>  <A href="../../../../../docs/manualpages/Vec/PetscLayout.html#PetscLayout">PetscLayout</A>       map=aomems-&gt;map;
<a name="line292">292: </a>  <A href="../../../../../docs/manualpages/Sys/PetscInt.html#PetscInt">PetscInt</A>          n_local = map-&gt;n,i,j;
<a name="line293">293: </a>  <A href="../../../../../docs/manualpages/Sys/PetscMPIInt.html#PetscMPIInt">PetscMPIInt</A>       rank,size,tag;
<a name="line294">294: </a>  <A href="../../../../../docs/manualpages/Sys/PetscInt.html#PetscInt">PetscInt</A>          *owner,*start,*nprocs,nsends,nreceives;
<a name="line295">295: </a>  <A href="../../../../../docs/manualpages/Sys/PetscInt.html#PetscInt">PetscInt</A>          nmax,count,*sindices,*rindices,idx,lastidx;
<a name="line296">296: </a>  <A href="../../../../../docs/manualpages/Sys/PetscInt.html#PetscInt">PetscInt</A>          *owners = aomems-&gt;map-&gt;range;
<a name="line297">297: </a>  MPI_Request       *send_waits,*recv_waits;
<a name="line298">298: </a>  MPI_Status        recv_status;
<a name="line299">299: </a>  <A href="../../../../../docs/manualpages/Sys/PetscMPIInt.html#PetscMPIInt">PetscMPIInt</A>       nindices,widx;
<a name="line300">300: </a>  <A href="../../../../../docs/manualpages/Sys/PetscInt.html#PetscInt">PetscInt</A>          *rbuf;
<a name="line301">301: </a>  <A href="../../../../../docs/manualpages/Sys/PetscInt.html#PetscInt">PetscInt</A>          n=napp,ip,ia;
<a name="line302">302: </a>  MPI_Status        *send_status;

<a name="line305">305: </a>  <A href="../../../../../docs/manualpages/Sys/PetscMemzero.html#PetscMemzero">PetscMemzero</A>(aomap_loc,n_local*<font color="#4169E1">sizeof</font>(<A href="../../../../../docs/manualpages/Sys/PetscInt.html#PetscInt">PetscInt</A>));

<a name="line307">307: </a>  <A href="http://www.mcs.anl.gov/mpi/www/www3/MPI_Comm_rank.html#MPI_Comm_rank">MPI_Comm_rank</A>(comm,&amp;rank);
<a name="line308">308: </a>  <A href="http://www.mcs.anl.gov/mpi/www/www3/MPI_Comm_size.html#MPI_Comm_size">MPI_Comm_size</A>(comm,&amp;size);
<a name="line309">309: </a>
<a name="line310">310: </a>  <font color="#B22222">/*  first count number of contributors (of from_array[]) to each processor */</font>
<a name="line311">311: </a>  <A href="../../../../../docs/manualpages/Sys/PetscMalloc.html#PetscMalloc">PetscMalloc</A>(2*size*<font color="#4169E1">sizeof</font>(<A href="../../../../../docs/manualpages/Sys/PetscInt.html#PetscInt">PetscInt</A>),&amp;nprocs);
<a name="line312">312: </a>  <A href="../../../../../docs/manualpages/Sys/PetscMemzero.html#PetscMemzero">PetscMemzero</A>(nprocs,2*size*<font color="#4169E1">sizeof</font>(<A href="../../../../../docs/manualpages/Sys/PetscInt.html#PetscInt">PetscInt</A>));
<a name="line313">313: </a>  <A href="../../../../../docs/manualpages/Sys/PetscMalloc.html#PetscMalloc">PetscMalloc</A>(n*<font color="#4169E1">sizeof</font>(<A href="../../../../../docs/manualpages/Sys/PetscInt.html#PetscInt">PetscInt</A>),&amp;owner);
<a name="line314">314: </a>
<a name="line315">315: </a>  j       = 0;
<a name="line316">316: </a>  lastidx = -1;
<a name="line317">317: </a>  <font color="#4169E1">for</font> (i=0; i&lt;n; i++) {
<a name="line318">318: </a>    <font color="#B22222">/* if indices are NOT locally sorted, need to start search at the beginning */</font>
<a name="line319">319: </a>    <font color="#4169E1">if</font> (lastidx &gt; (idx = from_array[i])) j = 0;
<a name="line320">320: </a>    lastidx = idx;
<a name="line321">321: </a>    <font color="#4169E1">for</font> (; j&lt;size; j++) {
<a name="line322">322: </a>      <font color="#4169E1">if</font> (idx &gt;= owners[j] &amp;&amp; idx &lt; owners[j+1]) {
<a name="line323">323: </a>        nprocs[2*j]  += 2; <font color="#B22222">/* num of indices to be sent - in pairs (ip,ia) */</font>
<a name="line324">324: </a>        nprocs[2*j+1] = 1; <font color="#B22222">/* send to proc[j] */</font>
<a name="line325">325: </a>        owner[i] = j;
<a name="line326">326: </a>        <font color="#4169E1">break</font>;
<a name="line327">327: </a>      }
<a name="line328">328: </a>    }
<a name="line329">329: </a>  }
<a name="line330">330: </a>  nprocs[2*rank]=nprocs[2*rank+1]=0; <font color="#B22222">/* do not receive from self! */</font>
<a name="line331">331: </a>  nsends = 0;
<a name="line332">332: </a>  <font color="#4169E1">for</font> (i=0; i&lt;size; i++) nsends += nprocs[2*i+1];

<a name="line334">334: </a>  <font color="#B22222">/* inform other processors of number of messages and max length*/</font>
<a name="line335">335: </a>  PetscMaxSum(comm,nprocs,&amp;nmax,&amp;nreceives);

<a name="line337">337: </a>  <font color="#B22222">/* allocate arrays */</font>
<a name="line338">338: </a>  <A href="../../../../../docs/manualpages/Sys/PetscObjectGetNewTag.html#PetscObjectGetNewTag">PetscObjectGetNewTag</A>((<A href="../../../../../docs/manualpages/Sys/PetscObject.html#PetscObject">PetscObject</A>)ao,&amp;tag);
<a name="line339">339: </a>  <A href="../../../../../docs/manualpages/Sys/PetscMalloc2.html#PetscMalloc2">PetscMalloc2</A>(nreceives*nmax,<A href="../../../../../docs/manualpages/Sys/PetscInt.html#PetscInt">PetscInt</A>,&amp;rindices,nreceives,MPI_Request,&amp;recv_waits);
<a name="line340">340: </a>  <A href="../../../../../docs/manualpages/Sys/PetscMalloc3.html#PetscMalloc3">PetscMalloc3</A>(2*n,<A href="../../../../../docs/manualpages/Sys/PetscInt.html#PetscInt">PetscInt</A>,&amp;sindices,nsends,MPI_Request,&amp;send_waits,nsends,MPI_Status,&amp;send_status);
<a name="line341">341: </a>  <A href="../../../../../docs/manualpages/Sys/PetscMalloc.html#PetscMalloc">PetscMalloc</A>(size*<font color="#4169E1">sizeof</font>(<A href="../../../../../docs/manualpages/Sys/PetscInt.html#PetscInt">PetscInt</A>),&amp;start);
<a name="line342">342: </a>
<a name="line343">343: </a>  <font color="#B22222">/* post receives: */</font>
<a name="line344">344: </a>  <font color="#4169E1">for</font> (i=0; i&lt;nreceives; i++) {
<a name="line345">345: </a>    <A href="http://www.mcs.anl.gov/mpi/www/www3/MPI_Irecv.html#MPI_Irecv">MPI_Irecv</A>(rindices+nmax*i,nmax,MPIU_INT,MPI_ANY_SOURCE,tag,comm,recv_waits+i);
<a name="line346">346: </a>  }

<a name="line348">348: </a>  <font color="#B22222">/* do sends:</font>
<a name="line349">349: </a><font color="#B22222">      1) starts[i] gives the starting index in svalues for stuff going to </font>
<a name="line350">350: </a><font color="#B22222">         the ith processor</font>
<a name="line351">351: </a><font color="#B22222">  */</font>
<a name="line352">352: </a>  start[0] = 0;
<a name="line353">353: </a>  <font color="#4169E1">for</font> (i=1; i&lt;size; i++) start[i] = start[i-1] + nprocs[2*i-2];
<a name="line354">354: </a>  <font color="#4169E1">for</font> (i=0; i&lt;n; i++) {
<a name="line355">355: </a>    j = owner[i];
<a name="line356">356: </a>    <font color="#4169E1">if</font> (j != rank){
<a name="line357">357: </a>      ip = from_array[i];
<a name="line358">358: </a>      ia = to_array[i];
<a name="line359">359: </a>      sindices[start[j]++]  = ip; sindices[start[j]++]  = ia;
<a name="line360">360: </a>    } <font color="#4169E1">else</font> { <font color="#B22222">/* compute my own map */</font>
<a name="line361">361: </a>      ip = from_array[i] -owners[rank];
<a name="line362">362: </a>      ia = to_array[i];
<a name="line363">363: </a>      aomap_loc[ip] = ia;
<a name="line364">364: </a>    }
<a name="line365">365: </a>  }

<a name="line367">367: </a>  start[0] = 0;
<a name="line368">368: </a>  <font color="#4169E1">for</font> (i=1; i&lt;size; i++) { start[i] = start[i-1] + nprocs[2*i-2];}
<a name="line369">369: </a>  <font color="#4169E1">for</font> (i=0,count=0; i&lt;size; i++) {
<a name="line370">370: </a>    <font color="#4169E1">if</font> (nprocs[2*i+1]) {
<a name="line371">371: </a>      <A href="http://www.mcs.anl.gov/mpi/www/www3/MPI_Isend.html#MPI_Isend">MPI_Isend</A>(sindices+start[i],nprocs[2*i],MPIU_INT,i,tag,comm,send_waits+count);
<a name="line372">372: </a>      count++;
<a name="line373">373: </a>    }
<a name="line374">374: </a>  }
<a name="line375">375: </a>  <font color="#4169E1">if</font> (nsends != count) <A href="../../../../../docs/manualpages/Sys/SETERRQ2.html#SETERRQ2">SETERRQ2</A>(comm,PETSC_ERR_SUP,<font color="#666666">"nsends %d != count %d"</font>,nsends,count);

<a name="line377">377: </a>  <font color="#B22222">/* wait on sends */</font>
<a name="line378">378: </a>  <font color="#4169E1">if</font> (nsends) {
<a name="line379">379: </a>    <A href="http://www.mcs.anl.gov/mpi/www/www3/MPI_Waitall.html#MPI_Waitall">MPI_Waitall</A>(nsends,send_waits,send_status);
<a name="line380">380: </a>  }

<a name="line382">382: </a>  <font color="#B22222">/* recvs */</font>
<a name="line383">383: </a>  count=0;
<a name="line384">384: </a>  <font color="#4169E1">for</font> (j= nreceives; j&gt;0; j--){
<a name="line385">385: </a>    <A href="http://www.mcs.anl.gov/mpi/www/www3/MPI_Waitany.html#MPI_Waitany">MPI_Waitany</A>(nreceives,recv_waits,&amp;widx,&amp;recv_status);
<a name="line386">386: </a>    <A href="http://www.mcs.anl.gov/mpi/www/www3/MPI_Get_count.html#MPI_Get_count">MPI_Get_count</A>(&amp;recv_status,MPIU_INT,&amp;nindices);
<a name="line387">387: </a>    rbuf = rindices+nmax*widx; <font color="#B22222">/* global index */</font>
<a name="line388">388: </a>
<a name="line389">389: </a>    <font color="#B22222">/* compute local mapping */</font>
<a name="line390">390: </a>    <font color="#4169E1">for</font> (i=0; i&lt;nindices; i+=2){ <font color="#B22222">/* pack aomap_loc */</font>
<a name="line391">391: </a>      ip = rbuf[i] - owners[rank]; <font color="#B22222">/* local index */</font>
<a name="line392">392: </a>      ia = rbuf[i+1];
<a name="line393">393: </a>      aomap_loc[ip] = ia;
<a name="line394">394: </a>    }
<a name="line395">395: </a>    count++;
<a name="line396">396: </a>  }

<a name="line398">398: </a>  <A href="../../../../../docs/manualpages/Sys/PetscFree.html#PetscFree">PetscFree</A>(start);
<a name="line399">399: </a>  <A href="../../../../../docs/manualpages/Sys/PetscFree3.html#PetscFree3">PetscFree3</A>(sindices,send_waits,send_status);
<a name="line400">400: </a>  <A href="../../../../../docs/manualpages/Sys/PetscFree2.html#PetscFree2">PetscFree2</A>(rindices,recv_waits);
<a name="line401">401: </a>  <A href="../../../../../docs/manualpages/Sys/PetscFree.html#PetscFree">PetscFree</A>(owner);
<a name="line402">402: </a>  <A href="../../../../../docs/manualpages/Sys/PetscFree.html#PetscFree">PetscFree</A>(nprocs);
<a name="line403">403: </a>  <font color="#4169E1">return</font>(0);
<a name="line404">404: </a>}

<a name="line406">406: </a>EXTERN_C_BEGIN
<a name="line409">409: </a><strong><font color="#4169E1"><a name="AOCreate_MemoryScalable"></a><A href="../../../../../docs/manualpages/Sys/PetscErrorCode.html#PetscErrorCode">PetscErrorCode</A> AOCreate_MemoryScalable(<A href="../../../../../docs/manualpages/AO/AO.html#AO">AO</A> ao)</font></strong>
<a name="line410">410: </a>{
<a name="line411">411: </a>  <A href="../../../../../docs/manualpages/Sys/PetscErrorCode.html#PetscErrorCode">PetscErrorCode</A>    ierr;
<a name="line412">412: </a>  <A href="../../../../../docs/manualpages/IS/IS.html#IS">IS</A>                isapp=ao-&gt;isapp,ispetsc=ao-&gt;ispetsc;
<a name="line413">413: </a>  const <A href="../../../../../docs/manualpages/Sys/PetscInt.html#PetscInt">PetscInt</A>    *mypetsc,*myapp;
<a name="line414">414: </a>  <A href="../../../../../docs/manualpages/Sys/PetscInt.html#PetscInt">PetscInt</A>          napp,n_local,N,i,start,*petsc;
<a name="line415">415: </a>  <A href="../../../../../docs/manualpages/Sys/MPI_Comm.html#MPI_Comm">MPI_Comm</A>          comm;
<a name="line416">416: </a>  AO_MemoryScalable *aomems;
<a name="line417">417: </a>  <A href="../../../../../docs/manualpages/Vec/PetscLayout.html#PetscLayout">PetscLayout</A>       map;
<a name="line418">418: </a>  <A href="../../../../../docs/manualpages/Sys/PetscMPIInt.html#PetscMPIInt">PetscMPIInt</A>       *lens,size,rank,*disp;
<a name="line419">419: </a>
<a name="line421">421: </a>  <font color="#B22222">/* create special struct aomems */</font>
<a name="line422">422: </a>  <A href="../../../../../docs/manualpages/Sys/PetscNewLog.html#PetscNewLog">PetscNewLog</A>(ao, AO_MemoryScalable, &amp;aomems);
<a name="line423">423: </a>  ao-&gt;data = (void*) aomems;
<a name="line424">424: </a>  <A href="../../../../../docs/manualpages/Sys/PetscMemcpy.html#PetscMemcpy">PetscMemcpy</A>(ao-&gt;ops,&amp;AOOps_MemoryScalable,<font color="#4169E1">sizeof</font>(<font color="#4169E1">struct _AOOps</font>));
<a name="line425">425: </a>  PetscObjectChangeTypeName((<A href="../../../../../docs/manualpages/Sys/PetscObject.html#PetscObject">PetscObject</A>)ao,AOMEMORYSCALABLE);

<a name="line427">427: </a>  <font color="#B22222">/* transmit all local lengths of isapp to all processors */</font>
<a name="line428">428: </a>  <A href="../../../../../docs/manualpages/Sys/PetscObjectGetComm.html#PetscObjectGetComm">PetscObjectGetComm</A>((<A href="../../../../../docs/manualpages/Sys/PetscObject.html#PetscObject">PetscObject</A>)isapp,&amp;comm);
<a name="line429">429: </a>  <A href="http://www.mcs.anl.gov/mpi/www/www3/MPI_Comm_size.html#MPI_Comm_size">MPI_Comm_size</A>(comm, &amp;size);
<a name="line430">430: </a>  <A href="http://www.mcs.anl.gov/mpi/www/www3/MPI_Comm_rank.html#MPI_Comm_rank">MPI_Comm_rank</A>(comm, &amp;rank);
<a name="line431">431: </a>  <A href="../../../../../docs/manualpages/Sys/PetscMalloc2.html#PetscMalloc2">PetscMalloc2</A>(size,<A href="../../../../../docs/manualpages/Sys/PetscMPIInt.html#PetscMPIInt">PetscMPIInt</A>, &amp;lens,size,<A href="../../../../../docs/manualpages/Sys/PetscMPIInt.html#PetscMPIInt">PetscMPIInt</A>,&amp;disp);
<a name="line432">432: </a>  <A href="../../../../../docs/manualpages/IS/ISGetLocalSize.html#ISGetLocalSize">ISGetLocalSize</A>(isapp,&amp;napp);
<a name="line433">433: </a>  <A href="http://www.mcs.anl.gov/mpi/www/www3/MPI_Allgather.html#MPI_Allgather">MPI_Allgather</A>(&amp;napp, 1, MPI_INT, lens, 1, MPI_INT, comm);

<a name="line435">435: </a>  N = 0;
<a name="line436">436: </a>  <font color="#4169E1">for</font>(i = 0; i &lt; size; i++) {
<a name="line437">437: </a>    disp[i] = N;
<a name="line438">438: </a>    N      += lens[i];
<a name="line439">439: </a>  }

<a name="line441">441: </a>  <font color="#B22222">/* If ispetsc is 0 then use "natural" numbering */</font>
<a name="line442">442: </a>  <font color="#4169E1">if</font> (napp) {
<a name="line443">443: </a>    <font color="#4169E1">if</font> (!ispetsc) {
<a name="line444">444: </a>      start = disp[rank];
<a name="line445">445: </a>      <A href="../../../../../docs/manualpages/Sys/PetscMalloc.html#PetscMalloc">PetscMalloc</A>((napp+1) * <font color="#4169E1">sizeof</font>(<A href="../../../../../docs/manualpages/Sys/PetscInt.html#PetscInt">PetscInt</A>), &amp;petsc);
<a name="line446">446: </a>      <font color="#4169E1">for</font> (i=0; i&lt;napp; i++) petsc[i] = start + i;
<a name="line447">447: </a>    } <font color="#4169E1">else</font> {
<a name="line448">448: </a>      <A href="../../../../../docs/manualpages/IS/ISGetIndices.html#ISGetIndices">ISGetIndices</A>(ispetsc,&amp;mypetsc);
<a name="line449">449: </a>      petsc = (<A href="../../../../../docs/manualpages/Sys/PetscInt.html#PetscInt">PetscInt</A>*)mypetsc;
<a name="line450">450: </a>    }
<a name="line451">451: </a>  }
<a name="line452">452: </a>
<a name="line453">453: </a>  <font color="#B22222">/* create a map with global size N - used to determine the local sizes of ao - shall we use local napp instead of N? */</font>
<a name="line454">454: </a>  <A href="../../../../../docs/manualpages/Vec/PetscLayoutCreate.html#PetscLayoutCreate">PetscLayoutCreate</A>(comm,&amp;map);
<a name="line455">455: </a>  map-&gt;bs = 1;
<a name="line456">456: </a>  map-&gt;N  = N;
<a name="line457">457: </a>  <A href="../../../../../docs/manualpages/Vec/PetscLayoutSetUp.html#PetscLayoutSetUp">PetscLayoutSetUp</A>(map);

<a name="line459">459: </a>  ao-&gt;N       = N;
<a name="line460">460: </a>  ao-&gt;n       = map-&gt;n;
<a name="line461">461: </a>  aomems-&gt;map = map;

<a name="line463">463: </a>  <font color="#B22222">/* create distributed indices app_loc: petsc-&gt;app and petsc_loc: app-&gt;petsc */</font>
<a name="line464">464: </a>  n_local = map-&gt;n;
<a name="line465">465: </a>  <A href="../../../../../docs/manualpages/Sys/PetscMalloc2.html#PetscMalloc2">PetscMalloc2</A>(n_local,<A href="../../../../../docs/manualpages/Sys/PetscInt.html#PetscInt">PetscInt</A>, &amp;aomems-&gt;app_loc,n_local,<A href="../../../../../docs/manualpages/Sys/PetscInt.html#PetscInt">PetscInt</A>,&amp;aomems-&gt;petsc_loc);
<a name="line466">466: </a>  PetscLogObjectMemory(ao,2*n_local*<font color="#4169E1">sizeof</font>(<A href="../../../../../docs/manualpages/Sys/PetscInt.html#PetscInt">PetscInt</A>));
<a name="line467">467: </a>  <A href="../../../../../docs/manualpages/Sys/PetscMemzero.html#PetscMemzero">PetscMemzero</A>(aomems-&gt;app_loc,n_local*<font color="#4169E1">sizeof</font>(<A href="../../../../../docs/manualpages/Sys/PetscInt.html#PetscInt">PetscInt</A>));
<a name="line468">468: </a>  <A href="../../../../../docs/manualpages/Sys/PetscMemzero.html#PetscMemzero">PetscMemzero</A>(aomems-&gt;petsc_loc,n_local*<font color="#4169E1">sizeof</font>(<A href="../../../../../docs/manualpages/Sys/PetscInt.html#PetscInt">PetscInt</A>));
<a name="line469">469: </a>  <A href="../../../../../docs/manualpages/IS/ISGetIndices.html#ISGetIndices">ISGetIndices</A>(isapp,&amp;myapp);

<a name="line471">471: </a>  AOCreateMemoryScalable_private(comm,napp,petsc,myapp,ao,aomems-&gt;app_loc);
<a name="line472">472: </a>  AOCreateMemoryScalable_private(comm,napp,myapp,petsc,ao,aomems-&gt;petsc_loc);

<a name="line474">474: </a>  <A href="../../../../../docs/manualpages/IS/ISRestoreIndices.html#ISRestoreIndices">ISRestoreIndices</A>(isapp,&amp;myapp);
<a name="line475">475: </a>  <font color="#4169E1">if</font> (napp){
<a name="line476">476: </a>    <font color="#4169E1">if</font> (ispetsc){
<a name="line477">477: </a>      <A href="../../../../../docs/manualpages/IS/ISRestoreIndices.html#ISRestoreIndices">ISRestoreIndices</A>(ispetsc,&amp;mypetsc);
<a name="line478">478: </a>    } <font color="#4169E1">else</font> {
<a name="line479">479: </a>      <A href="../../../../../docs/manualpages/Sys/PetscFree.html#PetscFree">PetscFree</A>(petsc);
<a name="line480">480: </a>    }
<a name="line481">481: </a>  }
<a name="line482">482: </a>  <A href="../../../../../docs/manualpages/Sys/PetscFree2.html#PetscFree2">PetscFree2</A>(lens,disp);
<a name="line483">483: </a>  <font color="#4169E1">return</font>(0);
<a name="line484">484: </a>}
<a name="line485">485: </a>EXTERN_C_END

<a name="line489">489: </a><font color="#B22222">/*@C</font>
<a name="line490">490: </a><font color="#B22222">   <A href="../../../../../docs/manualpages/AO/AOCreateMemoryScalable.html#AOCreateMemoryScalable">AOCreateMemoryScalable</A> - Creates a memory scalable application ordering using two integer arrays.</font>

<a name="line492">492: </a><font color="#B22222">   Collective on <A href="../../../../../docs/manualpages/Sys/MPI_Comm.html#MPI_Comm">MPI_Comm</A></font>

<a name="line494">494: </a><font color="#B22222">   Input Parameters:</font>
<a name="line495">495: </a><font color="#B22222">+  comm - MPI communicator that is to share <A href="../../../../../docs/manualpages/AO/AO.html#AO">AO</A></font>
<a name="line496">496: </a><font color="#B22222">.  napp - size of integer arrays</font>
<a name="line497">497: </a><font color="#B22222">.  myapp - integer array that defines an ordering</font>
<a name="line498">498: </a><font color="#B22222">-  mypetsc - integer array that defines another ordering (may be <A href="../../../../../docs/manualpages/Sys/PETSC_NULL.html#PETSC_NULL">PETSC_NULL</A> to </font>
<a name="line499">499: </a><font color="#B22222">             indicate the natural ordering, that is 0,1,2,3,...)</font>

<a name="line501">501: </a><font color="#B22222">   Output Parameter:</font>
<a name="line502">502: </a><font color="#B22222">.  aoout - the new application ordering</font>

<a name="line504">504: </a><font color="#B22222">   Level: beginner</font>

<a name="line506">506: </a><font color="#B22222">    Notes: The arrays myapp and mypetsc must contain the all the integers 0 to napp-1 with no duplicates; that is there cannot be any "holes"  </font>
<a name="line507">507: </a><font color="#B22222">           in the indices. Use <A href="../../../../../docs/manualpages/AO/AOCreateMapping.html#AOCreateMapping">AOCreateMapping</A>() or <A href="../../../../../docs/manualpages/AO/AOCreateMappingIS.html#AOCreateMappingIS">AOCreateMappingIS</A>() if you wish to have "holes" in the indices.</font>
<a name="line508">508: </a><font color="#B22222">           Comparing with <A href="../../../../../docs/manualpages/AO/AOCreateBasic.html#AOCreateBasic">AOCreateBasic</A>(), this routine trades memory with message communication.</font>

<a name="line510">510: </a><font color="#B22222">.keywords: <A href="../../../../../docs/manualpages/AO/AO.html#AO">AO</A>, create</font>

<a name="line512">512: </a><font color="#B22222">.seealso: <A href="../../../../../docs/manualpages/AO/AOCreateMemoryScalableIS.html#AOCreateMemoryScalableIS">AOCreateMemoryScalableIS</A>(), <A href="../../../../../docs/manualpages/AO/AODestroy.html#AODestroy">AODestroy</A>(), <A href="../../../../../docs/manualpages/AO/AOPetscToApplication.html#AOPetscToApplication">AOPetscToApplication</A>(), <A href="../../../../../docs/manualpages/AO/AOApplicationToPetsc.html#AOApplicationToPetsc">AOApplicationToPetsc</A>()</font>
<a name="line513">513: </a><font color="#B22222">@*/</font>
<a name="line514">514: </a><strong><font color="#4169E1"><a name="AOCreateMemoryScalable"></a><A href="../../../../../docs/manualpages/Sys/PetscErrorCode.html#PetscErrorCode">PetscErrorCode</A> <A href="../../../../../docs/manualpages/AO/AOCreateMemoryScalable.html#AOCreateMemoryScalable">AOCreateMemoryScalable</A>(<A href="../../../../../docs/manualpages/Sys/MPI_Comm.html#MPI_Comm">MPI_Comm</A> comm,<A href="../../../../../docs/manualpages/Sys/PetscInt.html#PetscInt">PetscInt</A> napp,const <A href="../../../../../docs/manualpages/Sys/PetscInt.html#PetscInt">PetscInt</A> myapp[],const <A href="../../../../../docs/manualpages/Sys/PetscInt.html#PetscInt">PetscInt</A> mypetsc[],<A href="../../../../../docs/manualpages/AO/AO.html#AO">AO</A> *aoout)</font></strong>
<a name="line515">515: </a>{
<a name="line517">517: </a>  <A href="../../../../../docs/manualpages/IS/IS.html#IS">IS</A>             isapp,ispetsc;
<a name="line518">518: </a>  const <A href="../../../../../docs/manualpages/Sys/PetscInt.html#PetscInt">PetscInt</A> *app=myapp,*petsc=mypetsc;

<a name="line521">521: </a>  <A href="../../../../../docs/manualpages/IS/ISCreateGeneral.html#ISCreateGeneral">ISCreateGeneral</A>(comm,napp,app,PETSC_USE_POINTER,&amp;isapp);
<a name="line522">522: </a>  <font color="#4169E1">if</font> (mypetsc){
<a name="line523">523: </a>    <A href="../../../../../docs/manualpages/IS/ISCreateGeneral.html#ISCreateGeneral">ISCreateGeneral</A>(comm,napp,petsc,PETSC_USE_POINTER,&amp;ispetsc);
<a name="line524">524: </a>  } <font color="#4169E1">else</font> {
<a name="line525">525: </a>    ispetsc = <A href="../../../../../docs/manualpages/Sys/PETSC_NULL.html#PETSC_NULL">PETSC_NULL</A>;
<a name="line526">526: </a>  }
<a name="line527">527: </a>  <A href="../../../../../docs/manualpages/AO/AOCreateMemoryScalableIS.html#AOCreateMemoryScalableIS">AOCreateMemoryScalableIS</A>(isapp,ispetsc,aoout);
<a name="line528">528: </a>  <A href="../../../../../docs/manualpages/IS/ISDestroy.html#ISDestroy">ISDestroy</A>(&amp;isapp);
<a name="line529">529: </a>  <font color="#4169E1">if</font> (mypetsc){
<a name="line530">530: </a>    <A href="../../../../../docs/manualpages/IS/ISDestroy.html#ISDestroy">ISDestroy</A>(&amp;ispetsc);
<a name="line531">531: </a>  }
<a name="line532">532: </a>  <font color="#4169E1">return</font>(0);
<a name="line533">533: </a>}

<a name="line537">537: </a><font color="#B22222">/*@C</font>
<a name="line538">538: </a><font color="#B22222">   <A href="../../../../../docs/manualpages/AO/AOCreateMemoryScalableIS.html#AOCreateMemoryScalableIS">AOCreateMemoryScalableIS</A> - Creates a memory scalable application ordering using two index sets.</font>

<a name="line540">540: </a><font color="#B22222">   Collective on <A href="../../../../../docs/manualpages/IS/IS.html#IS">IS</A></font>

<a name="line542">542: </a><font color="#B22222">   Input Parameters:</font>
<a name="line543">543: </a><font color="#B22222">+  isapp - index set that defines an ordering</font>
<a name="line544">544: </a><font color="#B22222">-  ispetsc - index set that defines another ordering (may be <A href="../../../../../docs/manualpages/Sys/PETSC_NULL.html#PETSC_NULL">PETSC_NULL</A> to use the</font>
<a name="line545">545: </a><font color="#B22222">             natural ordering)</font>

<a name="line547">547: </a><font color="#B22222">   Output Parameter:</font>
<a name="line548">548: </a><font color="#B22222">.  aoout - the new application ordering</font>

<a name="line550">550: </a><font color="#B22222">   Level: beginner</font>

<a name="line552">552: </a><font color="#B22222">    Notes: The index sets isapp and ispetsc must contain the all the integers 0 to napp-1 (where napp is the length of the index sets) with no duplicates; </font>
<a name="line553">553: </a><font color="#B22222">           that is there cannot be any "holes".</font>
<a name="line554">554: </a><font color="#B22222">           Comparing with <A href="../../../../../docs/manualpages/AO/AOCreateBasicIS.html#AOCreateBasicIS">AOCreateBasicIS</A>(), this routine trades memory with message communication.</font>
<a name="line555">555: </a><font color="#B22222">.keywords: <A href="../../../../../docs/manualpages/AO/AO.html#AO">AO</A>, create</font>

<a name="line557">557: </a><font color="#B22222">.seealso: <A href="../../../../../docs/manualpages/AO/AOCreateMemoryScalable.html#AOCreateMemoryScalable">AOCreateMemoryScalable</A>(),  <A href="../../../../../docs/manualpages/AO/AODestroy.html#AODestroy">AODestroy</A>()</font>
<a name="line558">558: </a><font color="#B22222">@*/</font>
<a name="line559">559: </a><strong><font color="#4169E1"><a name="AOCreateMemoryScalableIS"></a><A href="../../../../../docs/manualpages/Sys/PetscErrorCode.html#PetscErrorCode">PetscErrorCode</A>  <A href="../../../../../docs/manualpages/AO/AOCreateMemoryScalableIS.html#AOCreateMemoryScalableIS">AOCreateMemoryScalableIS</A>(<A href="../../../../../docs/manualpages/IS/IS.html#IS">IS</A> isapp,<A href="../../../../../docs/manualpages/IS/IS.html#IS">IS</A> ispetsc,<A href="../../../../../docs/manualpages/AO/AO.html#AO">AO</A> *aoout)</font></strong>
<a name="line560">560: </a>{
<a name="line562">562: </a>  <A href="../../../../../docs/manualpages/Sys/MPI_Comm.html#MPI_Comm">MPI_Comm</A>       comm;
<a name="line563">563: </a>  <A href="../../../../../docs/manualpages/AO/AO.html#AO">AO</A>             ao;

<a name="line566">566: </a>  <A href="../../../../../docs/manualpages/Sys/PetscObjectGetComm.html#PetscObjectGetComm">PetscObjectGetComm</A>((<A href="../../../../../docs/manualpages/Sys/PetscObject.html#PetscObject">PetscObject</A>)isapp,&amp;comm);
<a name="line567">567: </a>  <A href="../../../../../docs/manualpages/AO/AOCreate.html#AOCreate">AOCreate</A>(comm,&amp;ao);
<a name="line568">568: </a>  <A href="../../../../../docs/manualpages/AO/AOSetIS.html#AOSetIS">AOSetIS</A>(ao,isapp,ispetsc);
<a name="line569">569: </a>  <A href="../../../../../docs/manualpages/AO/AOSetType.html#AOSetType">AOSetType</A>(ao,AOMEMORYSCALABLE);
<a name="line570">570: </a>  *aoout = ao;
<a name="line571">571: </a>  <font color="#4169E1">return</font>(0);
<a name="line572">572: </a>}
</pre>
</body>

</html>
